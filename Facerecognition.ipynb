{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Facerecognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1CICCM8cLJrQtYbVigHu0u-HnjJehyRka",
      "authorship_tag": "ABX9TyPMghyvip2S5MLwlGfNVGji"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7g0uC3i4cWVx"
      },
      "source": [
        "pip install mtcnn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG8t4L6FFcVr"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "from matplotlib.patches import Circle\n",
        "from PIL import Image \n",
        "from numpy import savez_compressed\n",
        "from numpy import asarray\n",
        "from os import listdir\n",
        "from mtcnn.mtcnn import MTCNN\n",
        " \n",
        "#Extract face\n",
        "#we convert the image to RGB\n",
        "#Images needs to be covered to arrays, that's the only way it could be understood\n",
        "#The we detect using our MTCCN and find the face coordinate (w,h)\n",
        "def extract_face(image):\n",
        "  img = Image.open(image)         \n",
        "  img = img.convert('RGB')        \n",
        "  pixels = asarray(img1)             \n",
        "  detector = MTCNN()                 \n",
        "  find_face = detector.detect_faces(pixels)\n",
        "  x1,y1,w,h = find_face[0]['box']             \n",
        "  x1, y1 = abs(x1), abs(y1)\n",
        "  x2 = abs(x1+w)\n",
        "  y2 = abs(y1+h)\n",
        "  #locate the co-ordinates of face in the image\n",
        "  store_face = pixels[y1:y2,x1:x2]\n",
        "  plt.imshow(store_face)\n",
        "  image1 = Image.fromarray(store_face,'RGB')   \n",
        "#Facenet works with images with size 160 by 160, so we have to resize\n",
        "  re = image1.resize((160,160))             \n",
        "  face_array = asarray(re)                  \n",
        "  return face_array\n",
        " \n",
        " \n",
        "#find faces\n",
        "def load_faces(directory):\n",
        "  faces = []\n",
        "  i=1\n",
        "  for filename in listdir(directory):\n",
        "    path = directory + filename\n",
        "    all_faces = extract_image(path)\n",
        "    faces.append(all_faces)\n",
        "  return faces\n",
        " \n",
        " \n",
        "#Method to get the array of face data(trainX) and it's labels(trainY)\n",
        "def load_dataset(directory):\n",
        "  x, y = [],[]\n",
        "  i=1\n",
        "  for subdir in listdir(directory):\n",
        "    path = directory + subdir + '/'\n",
        "    #load all faces in subdirectory\n",
        "    faces = load_faces(path)\n",
        "    #create labels\n",
        "    labels = [subdir for _ in range(len(faces))]\n",
        "    #summarize\n",
        "    print(\"%d There are %d images in the class %s:\"%(i,len(faces),subdir))\n",
        "    x.extend(faces)\n",
        "    y.extend(labels)\n",
        "    i=i+1\n",
        "  return asarray(x),asarray(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ga8dUdEGEAME"
      },
      "source": [
        "trainX,trainy =load_dataset(r'/content/drive/My Drive/Colab Notebooks/faces94/train/')\n",
        "print(trainX.shape,trainy.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWxpTE6m37pF"
      },
      "source": [
        "testX, testY = load_dataset(r'/content/drive/My Drive/Colab Notebooks/faces94/test/')\n",
        "print(testX.shape,testY.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ni65dUW7U0ge"
      },
      "source": [
        " savez_compressed('/arrayface.npz',trainX,trainy, testX, testY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5dmJx9Qur6h"
      },
      "source": [
        "from keras.models import load_model\n",
        "from numpy import load\n",
        "from numpy import asarray"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3ZHJIMQutlK"
      },
      "source": [
        " \n",
        "# load the face dataset\n",
        "data = load('arrayface.npz')\n",
        "trainX, trainY, testX, testY = data['arr_0'], data['arr_1'] , data['arr_2'], data['arr_3']\n",
        "print('Loaded: ', trainX.shape, testX.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR9zMUvsu2MV"
      },
      "source": [
        "\n",
        "#This is where Facenet comes in\n",
        "model = load_model('facenet_keras.h5')\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqZQJz8ivHPr"
      },
      "source": [
        "import numpy as np\n",
        "from numpy import expand_dims\n",
        "def get_embedding(model, face_pixels):\n",
        "#convert pixel values to float32\n",
        "   face_pixels = face_pixels.astype('float32')\n",
        "# standardize pixel values across channels (global)\n",
        "   mean, std = face_pixels.mean(), face_pixels.std()\n",
        "   face_pixels = (face_pixels - mean) / std\n",
        "# transform face into one sample\n",
        "   samples = expand_dims(face_pixels, axis=0)\n",
        "# make prediction to get embedding\n",
        "   yhat = model.predict(samples)\n",
        "   return yhat[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpWSNX9VvMDR"
      },
      "source": [
        "from numpy import savez_compressed\n",
        "from numpy import reshape\n",
        "newTrainX = list()\n",
        "for face_pixels in trainX:\n",
        "    embedding = get_embedding(model, face_pixels)\n",
        "    newTrainX.append(embedding)\n",
        "newTrainX = asarray(newTrainX)\n",
        "print(newTrainX.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtS4iAAXvOqJ"
      },
      "source": [
        "newTestX = list()\n",
        "for face_pixels in testX:\n",
        " embedding = get_embedding(model, face_pixels)\n",
        " newTestX.append(embedding)\n",
        "newTestX = asarray(newTestX)\n",
        "print(newTestX.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPZ8l_UcvQ7V"
      },
      "source": [
        " \n",
        "#save your new face arrays with Facenet embeddings\n",
        "savez_compressed('arrayfaces_embeddings.npz', newTrainX, trainY, newTestX, testY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q6maxbPxqlJ"
      },
      "source": [
        " \n",
        " \n",
        "# develop a classifier for the Whole dataset\n",
        "#we are gonna use SVM for classification\n",
        "from numpy import load\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.svm import SVC\n",
        "# load dataset\n",
        "data = load('arrayfaces_embeddings.npz')\n",
        "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
        "print('Dataset: train=%d, test=%d' % (trainX.shape[0], testX.shape[0]))\n",
        "# normalize input vectors\n",
        "in_encoder = Normalizer(norm='l2')\n",
        "trainX = in_encoder.transform(trainX)\n",
        "testX = in_encoder.transform(testX)\n",
        "# label encode targets\n",
        "out_encoder = LabelEncoder()\n",
        "out_encoder.fit(trainy)\n",
        "trainy = out_encoder.transform(trainy)\n",
        "testy = out_encoder.transform(testy)\n",
        "# fit model\n",
        "model = SVC(kernel='linear', probability=True)\n",
        "model.fit(trainX, trainy)\n",
        "# predict\n",
        "yhat_train = model.predict(trainX)\n",
        "yhat_test = model.predict(testX)\n",
        "# score\n",
        "score_train = accuracy_score(trainy, yhat_train)\n",
        "score_test = accuracy_score(testy, yhat_test)\n",
        "# summarize\n",
        "print('Accuracy: train=%.3f, test=%.3f' % (score_train*100, score_test*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPylBntOyEZb"
      },
      "source": [
        " \n",
        "#Now, let's test our predicitons on a randomly picked test image\n",
        "from random import choice\n",
        "from numpy import load\n",
        "from numpy import expand_dims\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.svm import SVC\n",
        "from matplotlib import pyplot\n",
        "# load faces\n",
        "data = load('arrayface.npz')\n",
        "testX_faces = data['arr_2']\n",
        "# load face embeddings\n",
        "data = load('arrayfaces_embeddings.npz')\n",
        "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
        "# normalize input vectors\n",
        "in_encoder = Normalizer(norm='l2')\n",
        "trainX = in_encoder.transform(trainX)\n",
        "testX = in_encoder.transform(testX)\n",
        "# label encode targets\n",
        "out_encoder = LabelEncoder()\n",
        "out_encoder.fit(trainy)\n",
        "trainy = out_encoder.transform(trainy)\n",
        "testy = out_encoder.transform(testy)\n",
        "# fit model\n",
        "model = SVC(kernel='linear', probability=True)\n",
        "model.fit(trainX, trainy)\n",
        "# test model on a random example from the test dataset\n",
        "selection = choice([i for i in range(testX.shape[0])])\n",
        "random_face_pixels = testX_faces[selection]\n",
        "random_face_emb = testX[selection]\n",
        "random_face_class = testy[selection]\n",
        "random_face_name = out_encoder.inverse_transform([random_face_class])\n",
        "# prediction for the face\n",
        "samples = expand_dims(random_face_emb, axis=0)\n",
        "yhat_class = model.predict(samples)\n",
        "yhat_prob = model.predict_proba(samples)\n",
        "# get name\n",
        "class_index = yhat_class[0]\n",
        "class_probability = yhat_prob[0,class_index] * 100\n",
        "predict_names = out_encoder.inverse_transform(yhat_class)\n",
        "print('Predicted: %s (%.3f)' % (predict_names[0], class_probability))\n",
        "print('Expected: %s' % random_face_name[0])\n",
        "# plot for visibility\n",
        "pyplot.imshow(random_face_pixels)\n",
        "title = '%s (%.3f)' % (predict_names[0], class_probability)\n",
        "pyplot.title(title)\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}